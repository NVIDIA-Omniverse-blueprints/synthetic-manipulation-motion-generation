{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2ff454-b14a-4ef1-986c-9087c003ea53",
   "metadata": {},
   "source": [
    "# Imitation Learning Dataset Generation Notebook\n",
    "\n",
    "This notebook demonstrates how to generate additional datasets through imitation learning using Isaac Lab Mimic. The workflow consists of several key steps:\n",
    "\n",
    "1. **Configure basic parameters**: \n",
    "   - Task name\n",
    "   - Number of parallel environments\n",
    "   - Number of demonstrations to generate\n",
    "2. **Initialize the environment**: Instantiates the IsaacLab environment with configured parameters\n",
    "2. **Interactive Parameter Updates**: Allows customization of randomizable parameters\n",
    "3. **Data Generation**: Generates new demonstrations based on existing annotated datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4eee1",
   "metadata": {},
   "source": [
    "## Initial Configuration\n",
    "\n",
    "This cell sets up the basic configuration for data generation:\n",
    "\n",
    "1. **How to Modify**:\n",
    "   - Change `task` to your desired environment\n",
    "   - Adjust `num_envs` based on your GPU capability\n",
    "   - Set `generation_num_trials` to how many demos you want\n",
    "\n",
    "2. **Tips**:\n",
    "   - Start with 10 trials for testing, increase for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d91d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import create_task_input, create_num_trials_input\n",
    "\n",
    "task = create_task_input()\n",
    "num_envs = 1\n",
    "num_trials = create_num_trials_input()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc54d6a",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Run this cell to initialize the simulation environment. This sets up the necessary components for data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2cf0f-cf3c-4383-a233-216ff1f48c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from argparse import ArgumentParser, Namespace\n",
    "from isaaclab.app import AppLauncher\n",
    "\n",
    "parser = ArgumentParser()\n",
    "AppLauncher.add_app_launcher_args(parser)\n",
    "args_cli = parser.parse_args([])\n",
    "args_cli.enable_cameras = True\n",
    "args_cli.kit_args = \"--enable omni.videoencoding\"\n",
    "\n",
    "config = {\n",
    "    \"task\": task.value,  \n",
    "    \"num_envs\": num_envs,                                       \n",
    "    \"generation_num_trials\": num_trials.value,                         \n",
    "    \"input_file\": \"datasets/annotated_dataset.hdf5\",     \n",
    "    \"output_file\": \"datasets/generated_dataset.hdf5\", \n",
    "    \"pause_subtask\": False,\n",
    "    \"enable\": \"omni.kit.renderer.capture\",\n",
    "}\n",
    "\n",
    "# Update the default configuration\n",
    "args_dict = vars(args_cli)\n",
    "args_dict.update(config)\n",
    "args_cli = Namespace(**args_dict)\n",
    "\n",
    "# Now launch the simulator with the final configuration\n",
    "app_launcher = AppLauncher(args_cli)\n",
    "simulation_app = app_launcher.app\n",
    "\n",
    "import asyncio\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import isaaclab_mimic.envs  # noqa: F401\n",
    "from isaaclab_mimic.datagen.generation import env_loop, setup_env_config, setup_async_generation\n",
    "from isaaclab_mimic.datagen.utils import get_env_name_from_dataset, setup_output_paths, interactive_update_randomizable_params, reset_env\n",
    "from isaaclab.managers import ObservationTermCfg as ObsTerm\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "\n",
    "import isaaclab_tasks  # noqa: F401\n",
    "num_envs = args_cli.num_envs\n",
    "\n",
    "# Setup output paths and get env name\n",
    "output_dir, output_file_name = setup_output_paths(args_cli.output_file)\n",
    "env_name = args_cli.task or get_env_name_from_dataset(args_cli.input_file)\n",
    "\n",
    "# Configure environment\n",
    "env_cfg, success_term = setup_env_config(\n",
    "    env_name=env_name,\n",
    "    output_dir=output_dir,\n",
    "    output_file_name=output_file_name,\n",
    "    num_envs=num_envs,\n",
    "    device=args_cli.device,\n",
    "    generation_num_trials=args_cli.generation_num_trials,\n",
    ")\n",
    "# Set observation output directory\n",
    "for obs in vars(env_cfg.observations.rgb_camera).values():\n",
    "    if not isinstance(obs, ObsTerm):\n",
    "        continue\n",
    "    obs.params[\"image_path\"] = os.path.join(ISAACLAB_OUTPUT_DIR, obs.params[\"image_path\"])\n",
    "env_cfg.observations\n",
    "\n",
    "\n",
    "# create environment\n",
    "env = gym.make(env_name, cfg=env_cfg)\n",
    "\n",
    "# set seed for generation\n",
    "random.seed(env.unwrapped.cfg.datagen_config.seed)\n",
    "np.random.seed(env.unwrapped.cfg.datagen_config.seed)\n",
    "torch.manual_seed(env.unwrapped.cfg.datagen_config.seed)\n",
    "\n",
    "# reset before starting\n",
    "reset_env(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd57b1",
   "metadata": {},
   "source": [
    "## Interactive Parameter Updates\n",
    "\n",
    "This section provides interactive sliders and controls to adjust various environment parameters in real-time:\n",
    "\n",
    "1. **What You'll See**:\n",
    "   - Sliders for numerical values\n",
    "   - Range inputs for min/max settings\n",
    "   - Current value displays\n",
    "   - Parameter names and allowed ranges\n",
    "\n",
    "2. **How to Use**:\n",
    "   - Move the sliders to adjust values\n",
    "   - Watch the environment update in real-time\n",
    "\n",
    "3. **Tips**:\n",
    "   - Start with small adjustments to understand their effects\n",
    "\n",
    "Note: These adjustments will affect how new demonstrations are generated, so take time to experiment with different settings to achieve desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27b67f-d051-45e5-878f-2f6e1e6822f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event_term in env.unwrapped.event_manager._mode_term_cfgs[\"reset\"]:\n",
    "    if hasattr(event_term, \"randomizable_params\") and event_term.randomizable_params is not None:\n",
    "        print(f\"Updating parameters for event: {event_term.func.__name__}\")\n",
    "        interactive_update_randomizable_params(event_term, event_term.randomizable_params, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d35f42",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Run this cell to start generating demonstrations using the parameters you've configured. The process will:\n",
    "- Generate the specified number of demonstrations\n",
    "- Save successful demonstrations to your output file\n",
    "- Show progress as demonstrations are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cd632-b2a5-4e23-8ad4-3df7e32a2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and run async data generation\n",
    "async_components = setup_async_generation(\n",
    "    env=env,\n",
    "    num_envs=args_cli.num_envs,\n",
    "    input_file=args_cli.input_file,\n",
    "    success_term=success_term,\n",
    "    pause_subtask=args_cli.pause_subtask\n",
    ")\n",
    "\n",
    "try:\n",
    "    asyncio.ensure_future(asyncio.gather(*async_components['tasks']))\n",
    "    env_loop(env, async_components['action_queue'], \n",
    "            async_components['info_pool'], async_components['event_loop'])\n",
    "except asyncio.CancelledError:\n",
    "    print(\"Tasks were cancelled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd54f9-b002-4028-9699-bd85827b98e3",
   "metadata": {},
   "source": [
    "# Cosmos\n",
    "## Video Generation\n",
    "The normals are used to apply shading to the semantic segmentation which produces an input that works very well for the Cosmos model that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c599698-a590-4eca-a53b-dba6011be42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import create_camera_input, create_start_frame_input\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR, COSMOS_OUTPUT_DIR\n",
    "\n",
    "VIDEO_LENGTH = 120   # Suggested length is between 120 and 200\n",
    "START_FRAME = 0\n",
    "\n",
    "camera_selection = create_camera_input(ISAACLAB_OUTPUT_DIR)\n",
    "start_frame = create_start_frame_input(ISAACLAB_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d446c26-d7e3-4515-9818-c8bf4f93da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Video\n",
    "from notebook_utils import encode_video, ISAACLAB_OUTPUT_DIR\n",
    "\n",
    "video_filepath = os.path.join(ISAACLAB_OUTPUT_DIR, \"shaded_segmentation.mp4\")\n",
    "encode_video(ISAACLAB_OUTPUT_DIR, start_frame.value, VIDEO_LENGTH, camera_selection.value, video_filepath)\n",
    "\n",
    "display(Video(video_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa2e8a-0748-4201-b6e2-6582455bea85",
   "metadata": {},
   "source": [
    "## Cosmos Generation\n",
    "### Get API Keys\n",
    "#### NVIDIA NGC Catalog key\n",
    "The NVIDIA NGC API Key is used in this blueprint in order to pull the default router models from NGC as well as the NVIDIA Triton Inference Server docker image which is used to run those models. Refer to [Generating NGC API Keys](https://docs.nvidia.com/ngc/gpu-cloud/ngc-user-guide/index.html#generating-api-key) in the NVIDIA NGC User Guide for more information.\n",
    "\n",
    "#### NVIDIA API Catalog key\n",
    "The LLM router is responsible for routing requests between foundational LLM models. In this example, we will use NVIDIA NIMs. In order to access these LLMs we will use a NVIDIA API Catalog key, which is separate from the NVIDIA NGC API key used above. You can alternatively use other LLM models or even on-premise models. To do so, you would update the router configuration file which will be discussed later.\n",
    "\n",
    "1. Navigate to **[NVIDIA API Catalog](https://build.nvidia.com/explore/discover)**.\n",
    "2. Select a model, such as cosmos-1.0-diffusion-7b.\n",
    "3. Select an **Input** option. The following example is of a model that offers a Docker option. Not all of the models offer this option, but all include a “Get API Key” link\n",
    "<img src=\"https://docscontent.nvidia.com/dims4/default/d6307a8/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_docker_tab.png\">\n",
    "4. Click **Get API Key**.\n",
    "<img src=\"https://docscontent.nvidia.com/dims4/default/c6e2096/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_get_api_key.png\">\n",
    "5. Select **\\\"Generate Key\\\"**\n",
    "<img src=\"https://docscontent.nvidia.com/dims4/default/e7c4057/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_generate_key.png\">\n",
    "6. **Copy your key** and store it in a secure place. Do not share it.\n",
    "<img src=\"https://docscontent.nvidia.com/dims4/default/4b0710a/2147483647/strip/true/crop/1920x919+0+0/resize/2880x1378!/format/webp/quality/90/?url=https%3A%2F%2Fk3-prod-nvidia-docs.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fsphinx%2F00000192-bfa6-da2c-a1f2-ffbf41aa0000%2Fnim%2Flarge-language-models%2Flatest%2F_images%2Fbuild_copy_key.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf11a7-4375-478c-a066-f109ce847601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "api_key_widget = widgets.Text(value=\"\", placeholder=\"Enter API Key Here\", description=\"API Key:\", style={'description_width': 'initial'})\n",
    "display(api_key_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe33b4-3943-4716-92cd-e3cbc642ff6d",
   "metadata": {},
   "source": [
    "### Using the Cosmos Model\n",
    "\n",
    "The Cosmos model is parametrized with several available parameters which alter the output in various ways:\n",
    "- prompt: Text prompt for the video generation.\n",
    "- seed: Seed for the random number generator.\n",
    "- control_weight: A float value between 0 and 1 that controls the strength of the controlnet transformation.\n",
    "- sigma_max: A float value representing the maximum sigma. Lower values result in less change from the original input while a larger values allows for more change but may diverge more from the input scene.\n",
    "- use_canny_edge: A boolean indicating whether to use the canny edges from the input video.\n",
    "- blur_strength: A string representing the blur strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47b996-132e-416a-a94d-ba0548bfdcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import create_variable_dropdowns, create_cosmos_params\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR, COSMOS_OUTPUT_DIR\n",
    "\n",
    "prompt_manager = create_variable_dropdowns(\"stacking_prompt.toml\")\n",
    "cosmos_params = create_cosmos_params(ISAACLAB_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ad2d0-7fc3-45ad-88ed-748e34b6eafd",
   "metadata": {},
   "source": [
    "## Generate with Cosmos\n",
    "---\n",
    "**NOTE:** Generation generally takes between 1 to 3 minutes\n",
    "\n",
    "---\n",
    "\n",
    "### Tips\n",
    "- To increase prompt adherence, try increasing the `Sigma Max` value and/or `Blur Strength`\n",
    "- To reduce divergence from the input scene, try increasing the `Control Weight` and/or decreasing `Sigma Max`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80ae7d-2698-41be-8812-fc1597c208f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nvcf_async import api_call_async\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "from notebook_widgets import create_download_link\n",
    "from IPython.display import Video\n",
    "\n",
    "params = {k: w.value for k, w in cosmos_params.items()}\n",
    "video_filepath = os.path.join(ISAACLAB_OUTPUT_DIR, params.pop(\"input_video\"))\n",
    "params[\"prompt\"] = f\"\\\"{prompt_manager.prompt}\\\"\"\n",
    "params[\"input_video\"] = \"image_0\"\n",
    "params[\"blur_strength\"] = f\"\\\"{params['blur_strength'].lower().replace(' ', '_')}\\\"\"\n",
    "\n",
    "if not api_key_widget.value:\n",
    "    raise ValueError(\"Enter a valid API Key to proceed.\")\n",
    "\n",
    "if not os.path.exists(video_filepath):\n",
    "    raise ValueError(f\"Video file not found at {video_filepath}\")\n",
    "\n",
    "result = await api_call_async(\n",
    "    token=api_key_widget.value,\n",
    "    params=params,\n",
    "    filepaths=[video_filepath],\n",
    ")\n",
    "\n",
    "if result.status_code == 200 and result.output is not None and \"video\" in result.output:\n",
    "    # save the output video\n",
    "    os.makedirs(COSMOS_OUTPUT_DIR, exist_ok=True)\n",
    "    output_path = f\"{COSMOS_OUTPUT_DIR}/cosmos_{params['seed']}.mp4\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(result.output[\"video\"])\n",
    "    print(f\"Output video saved to {output_path}\")\n",
    "    display(Video(output_path))\n",
    "    display(create_download_link(output_path, link_text=f\"Download Video: {output_path}\"))\n",
    "else:\n",
    "    display(f\"An unexpected error occurred: {result.response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07e4772-f625-4775-bf56-b0a297028eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close simulation app\n",
    "simulation_app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bd2fe-e628-4e7d-bcbd-c73bafcf4648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_isaaclab",
   "language": "python",
   "name": "env_isaaclab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
